# 01-RAG 是什麼與適用場景

## 你將學到（Learning Objectives）

- 能用一句話解釋 **RAG 在系統裡做了什麼**
- 能判斷你的需求是「需要 RAG」還是「其實只要搜尋/FAQ/規則」
- 能把需求轉成可量化的成功標準（KPI / SLO）

## 本章地圖

- **適合用在**：要判斷是不是該用 RAG、用在哪些問題類型時。
- **你會做出**：場景判斷準則與最小可行的系統邊界。
- **最可能踩雷**：把「需要推理/需要外部事實」混在一起，導致誤用 RAG。

## 一句話定義

**RAG = 先檢索找證據，再用 LLM 依證據生成答案（最好附引用）。**

它把 LLM 從「憑參數記憶回答」拉回到「以企業/團隊文件為依據回答」。

## 什麼時候適合用 RAG

- **知識會更新**：制度、流程、產品規格、FAQ 會變動，不能等模型訓練/微調
- **答案需要可追溯**：必須提供來源或引用（例如內規、合約、技術規格）
- **文件量大且分散**：散落在多處（wiki、PDF、PRD、設計文、SOP）
- **工程團隊要可控**：要能透過檢索與資料治理去「迭代變準」

## 什麼時候不一定需要 RAG

- **問題本質是結構化查詢**：例如「查某客戶最近 30 天交易」→ 應該走 DB/報表
- **答案可以寫死或規則化**：小型 FAQ、固定流程 → 先做搜尋/FAQ，成本更低
- **你沒有資料治理能力**：來源不可信、沒有版本、權限不清楚 → 先把資料管起來

## RAG 的常見誤區

- **把 RAG 當成模型本身**：其實 RAG 是一個「檢索 + 生成」的系統設計
- **只追求向量相似度**：真正決定可用性的是切分、metadata、rerank、評估與觀測
- **沒有不可回答策略**：這會讓系統在證據不足時仍硬答，造成信任崩壞

## 最小可行 RAG（MVP）長什麼樣

MVP 的目標不是「做最強」，而是用最少的元件跑通端到端流程，並且**可回放、可量測、可迭代**。你要交付的不是一個「向量庫」，而是一條能穩定運作的資料流：**文件進來 → 變成可檢索的 chunks → 找回證據 → 依證據回答 → 全程可追溯**。

### 端到端最小流程（你一定要跑通的 6 步）

1. **收集資料**：把「使用者真的會問」的文件拉一小批進來（先求代表性，不求完整）
2. **清理與版本化**：同一份文件要能分辨「新版/舊版」，並保留來源（否則你無法解釋答案從哪來）
3. **切分 chunks**：把文件拆成能被檢索命中的粒度（太大找不準、太小會缺上下文）
4. **向量化與入庫**：把 chunks 轉 embedding 存進向量庫（同時把 metadata 一起存好）
5. **檢索與過濾**：先做權限/租戶/文件類型 filter，再做 top-k 相似度找回候選證據
6. **生成與引用**：把證據組裝進 prompt，要求引用；證據不足就拒答或追問

如果你只能記一件事：**MVP 的核心是「資料與回放」**。沒有回放，你永遠不知道是資料爛、切分爛、檢索爛，還是 prompt 爛。

### 你要交付的工件（讓團隊能驗收「真的有做出 MVP」）

- **一條 ingest 流程**：把文件（PDF/HTML/Markdown）轉成 chunks，並能重跑（同一份文件重跑不會產生一堆重複資料）
- **一個可用的問答介面**：先用一個 API/簡易頁面就好，重點是能把 query 送進去並拿回「答案 + 引用」
- **一套最小資料模型**：能在 DB 裡對應 `document → chunks → embeddings → metadata`，並支援版本與權限欄位
- **一份可回放的問答紀錄**：每次問答都能回放「當時檢索到了什麼、最後引用了什麼、為什麼這樣答」
- **一個小型評估集**：先做 20～50 題真實問題（含標準答案或至少「應引用哪些文件」），用來避免越改越爛

下面是一個「最小可回放」的 log 長相（不求漂亮，但求你能 debug）：

```json
{
  "query": "如何申請設備採購？",
  "filters": {"tenant_id": "lab", "doc_type": ["SOP"], "acl": ["employee"]},
  "retrieval": [{"chunk_id": "doc123#c07", "score": 0.82}, {"chunk_id": "doc123#c03", "score": 0.79}],
  "citations": [{"chunk_id": "doc123#c07"}, {"chunk_id": "doc123#c03"}],
  "latency_ms": {"retrieve": 120, "generate": 1400},
  "cost": {"prompt_tokens": 1800, "completion_tokens": 260},
  "index_version": "2026-01-17",
  "embedding_model": "text-embedding-3-large",
  "llm_model": "gpt-4.1-mini"
}
```

### 必備元件（不做這些就不算 MVP）

- **資料（先小、但要乾淨）**
  - **範圍**：先用 50～500 篇中文文件就夠，但要涵蓋你最在意的 3～5 類問題（例如：流程、規範、FAQ、產品規格）。
  - **來源可追溯**：每篇文件至少要有 `source`（URL/路徑）、`title`、`last_updated_at`、`version`（或 hash）。
  - **權限先定清楚**：就算一開始只有「全員可讀」，也要先把 `tenant_id` / `acl` 欄位放進 metadata，避免之後重做索引。

- **切分（讓「命中」變得可能）**
  - **起手式**：每段 200～500 中文字左右，並保留標題階層（章/節/小節），讓引用可讀。
  - **不是只看字數**：遇到條列/表格/FAQ，優先「以結構切分」；否則 chunk 會破碎到無法回答「步驟/條件/例外」。
  - **每個 chunk 都要可定位**：至少帶 `doc_id`、`chunk_id`、`section_path`（例如：`第2章 > 2.3 權限`）。

- **向量庫（先求好維運）**
  - **推薦**：Postgres + pgvector，因為同一套系統就能存資料、存 metadata、做權限 filter，也好備份與稽核。
  - **你在 MVP 階段要能做的事**：查到某次回答引用了哪些 chunks、這些 chunks 來自哪份文件哪個版本、以及當時的 embedding 模型版本。

- **檢索（先可控、再追極致）**
  - **先過濾再相似度**：先用 metadata filter（權限/租戶/文件類型/版本）縮小集合，再做向量相似度 top-k。
  - **top-k 不是越大越好**：k 太大會把雜訊塞進 prompt；MVP 先讓 k 可調、並記錄每次查詢的命中狀況。

- **生成（把可靠性當成預設）**
  - **答案必須附引用**：至少做到「每個關鍵主張對應 1～N 個引用」。
  - **證據不足的策略要寫死**：要嘛拒答、要嘛追問（例如：缺少版本/範圍/產品型號時先問清楚），不要硬答。

- **觀測與回放（沒有它就不能迭代）**
  - **每次問答最少要記錄**：query、使用的 filter、候選 chunks（含分數與 metadata）、最後放進 prompt 的引用、模型輸出、延遲、token/成本。
  - **要能重放**：給定同一個 query + 同一個索引版本，你要能重建「當時看到了哪些候選 chunks、為什麼最後引用了這些」。

> [!TIP]
> **起手式**：先把「權限欄位（ACL/租戶）」與「文件版本」放進 metadata；沒有這兩個，後面很難安全地上線迭代。

### 起手式參數（可直接採用，之後再用評估調）

| 項目 | 建議起始值 | 為什麼 |
| --- | --- | --- |
| chunk 長度 | 200～500 中文字 | 太大不容易命中，太小容易缺上下文 |
| chunk overlap | 50～100 中文字（可選） | 降低段落邊界把關鍵句切斷的機率 |
| top-k | 5～10 | 先讓 prompt 不被雜訊淹沒 |
| metadata filter | 先做權限/租戶/文件類型 | 這比任何相似度技巧都更「有用且安全」 |
| 不可回答策略 | 拒答或追問（二選一先做穩） | 避免證據不足硬答造成信任崩壞 |

### 可先不做（避免一開始就過度設計）

- **Rerank / 多路召回**：先用 top-k 跑通資料→檢索→生成→評估，再加二階段檢索；否則你會在資料很爛時「把排序做得很辛苦」
- **複雜工作流/Agent**：先把問答品質與引用做穩，再導入工具使用；否則你會把「找不到證據」誤判成「需要 Agent」
- **花式向量庫與分散式架構**：先以可維運、可觀測為主；在資料治理未成熟前放大系統複雜度，只會讓問題更難定位

### MVP 的驗收標準（最小可驗收）

- **可追溯**：答案能附上引用（至少到「文件 + 章節/段落」），且點開引用能看到原文
- **可控**：證據不足時能拒答或追問，且行為一致可預期（不會同題不同次亂跳）
- **可回放**：可以重放一次問答，看到同一批候選 chunks、最終引用、以及當次使用的索引/模型版本
- **可量測**：至少能量到命中率（retrieval hit）、延遲、成本與失敗類型（找不到、找錯、引用不對、證據不足硬答）

## 本章小結

- RAG 適合「答案依賴可追溯資料」且資料會變動的問題，而非純常識或純推理。
- 成功的關鍵不是向量庫，而是資料工程、權限與可回放的治理能力。
- 先把不可回答與澄清策略納入設計，避免上線後硬答造成風險。

## 延伸閱讀

- [03-成功標準與KPI（正確率-覆蓋率-成本-延遲）](03-成功標準與KPI（正確率-覆蓋率-成本-延遲）.md)
- [02-Prompt模板（可回答-不可回答-追問澄清）](../05-生成策略（把答案變可靠）/02-Prompt模板（可回答-不可回答-追問澄清）.md)
- [02-FAQ（常見誤解與坑）](../11-附錄/02-FAQ（常見誤解與坑）.md)
